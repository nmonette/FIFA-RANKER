{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "f9a4b88c"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "from urllib.request import Request, urlopen, ProxyHandler, build_opener, install_opener, HTTPError\n",
        "import pandas as pd\n",
        "from random import randrange\n",
        "from time import sleep\n",
        "from json import loads\n",
        "import requests\n",
        "from IPython.display import Audio\n",
        "from collections import defaultdict\n",
        "import numpy as np"
      ],
      "id": "f9a4b88c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f855bb91"
      },
      "source": [
        "# Scraping FUTBIN for Name, Popularity Values"
      ],
      "id": "f855bb91"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdu4NC4oRYf5"
      },
      "outputs": [],
      "source": [
        "## Getting User Agents and Proxies\n",
        "def get_proxies():\n",
        "    global https_proxies, http_proxies, user_agents\n",
        "    req = requests.get('https://proxylist.geonode.com/api/proxy-list?limit=500&page=1&sort_by=lastChecked&sort_type=desc&protocols=http').json()['data']\n",
        "    http_proxies = [r'http://' + req[q][\"ip\"] + f\":{req[q]['port']}\" for q in range(len(req))]\n",
        "    req = requests.get('https://proxylist.geonode.com/api/proxy-list?limit=500&page=1&sort_by=lastChecked&sort_type=desc&protocols=https').json()['data']\n",
        "    https_proxies = [r'https://' + req[q][\"ip\"] + f\":{req[q]['port']}\" for q in range(len(req))]\n",
        "    user_agents = open(\"/content/drive/MyDrive/user_agents1.txt\").readlines()\n",
        "    user_agents = [i.strip() for i in user_agents]\n",
        "\n",
        "#     req = loads(open('proxies.txt').read())['data']\n",
        "#     proxies = [r'http://' + req[q][\"ip\"] + f\":{req[q]['port']}\" for q in range(len(req))]\n",
        "\n",
        "    bruhh = []\n",
        "    bruhs = []\n",
        "    for i in range(1,5):\n",
        "        try:\n",
        "            req = Request(\n",
        "                url=f'https://hidemy.name/en/proxy-list/?type=h&start={64*i}#list', \n",
        "                headers={'User-Agent': user_agents[randrange(0,len(user_agents))]}\n",
        "            )\n",
        "            webpage = urlopen(req)#, proxies={'http':proxies[randrange(0, len(proxies))]}).read()\n",
        "            x = pd.read_html(webpage)[0]\n",
        "            bruhh.append(x)#[[\"IP address\"], [\"Port\"]])#[[\"IP address\"], [\"Port\"]])\n",
        "\n",
        "        except Exception as e:\n",
        "            break        \n",
        "          \n",
        "    bruhh = pd.concat(bruhh)\n",
        "    for i in range(bruhh.shape[0]):\n",
        "        http_proxies.append(\"http://\" + bruhh[\"IP address\"].iloc[i] + ':' + f'{bruhh[\"Port\"].iloc[i]}')\n",
        "\n",
        "\n",
        "    for i in range(1,5):\n",
        "        try:\n",
        "            req = Request(\n",
        "                url=f'https://hidemy.name/en/proxy-list/?type=s&start={64*i}#list', \n",
        "                headers={'User-Agent': user_agents[randrange(0,len(user_agents))]}\n",
        "            )\n",
        "            webpage = urlopen(req)#, proxies={'http':proxies[randrange(0, len(proxies))]}).read()\n",
        "            x = pd.read_html(webpage)[0]\n",
        "            bruhs.append(x)#[[\"IP address\"], [\"Port\"]])#[[\"IP address\"], [\"Port\"]])\n",
        "\n",
        "        except Exception as e:\n",
        "            break \n",
        "\n",
        "    bruhs = pd.concat(bruhs)\n",
        "    for i in range(bruhs.shape[0]):\n",
        "        https_proxies.append(\"https://\" + bruhs[\"IP address\"].iloc[i] + ':' + f'{bruhs[\"Port\"].iloc[i]}')  \n",
        "\n",
        "    \n",
        "get_proxies()"
      ],
      "id": "Wdu4NC4oRYf5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bb74c6ff"
      },
      "outputs": [],
      "source": [
        "columns = [\n",
        " #'name',\n",
        " 'rat',\n",
        " 'position',\n",
        " 'pace',\n",
        " 'acceleration',\n",
        " 'sprintspeed',\n",
        " 'shooting',\n",
        " 'positioning',\n",
        " 'finishing',\n",
        " 'shotpower',\n",
        " 'longshotsaccuracy',\n",
        " 'volleys',\n",
        " 'penalties',\n",
        " 'passing',\n",
        " 'vision',\n",
        " 'crossing',\n",
        " 'freekickaccuracy',\n",
        " 'shortpassing',\n",
        " 'longpassing',\n",
        " 'curve',\n",
        " 'dribblingp',\n",
        " 'agility',\n",
        " 'balance',\n",
        " 'reactions',\n",
        " 'ballcontrol',\n",
        " 'dribbling',\n",
        " 'composure',\n",
        " 'defending',\n",
        " 'interceptions',\n",
        " 'headingaccuracy',\n",
        " 'marking',\n",
        " 'standingtackle',\n",
        " 'slidingtackle',\n",
        " 'heading',\n",
        " 'jumping',\n",
        " 'stamina',\n",
        " 'strength',\n",
        " 'aggression',\n",
        " 'traits',\n",
        " 'xbox_gp',\n",
        " 'ps4_gp',\n",
        " 'pop'\n",
        "]\n",
        "    \n",
        "def get_players(req,year):\n",
        "    bs = BeautifulSoup(req)\n",
        "    def v(s):\n",
        "        if type(s) == str:\n",
        "            return f\"/{year}/player/\" in s\n",
        "        return False\n",
        "    players = bs.find_all(href=v)\n",
        "    return players\n",
        "\n",
        "def get_stats(req):\n",
        "    bs = BeautifulSoup(req)\n",
        "    stats1 = bs.find_all(\"div\", class_=\"stat_val\")\n",
        "    votes = bs.find_all(\"span\", class_=\"total_votes\")\n",
        "    v1 = (int(votes[1].contents[0]))\n",
        "    v0 = (int(votes[0].contents[0]))\n",
        "    votes = v1 - v0\n",
        "    pos = bs.find(\"div\", class_=\"pcdisplay-pos\")\n",
        "    rat = bs.find(\"div\", class_=\"pcdisplay-rat\")\n",
        "    ps4_gp = bs.find_all(\"div\", class_=\"ps4-pgp-data\")\n",
        "    ps4_gp = ps4_gp[-1].contents[0].strip()\n",
        "    \n",
        "    xbox_gp = bs.find_all(\"div\", class_=\"xbox-pgp-data hide\")\n",
        "    xbox_gp = xbox_gp[-1].contents[0].strip()\n",
        "    traits = [i.contents[0] for i in bs.find_all(\"div\", class_=\"trait-name-val\")]\n",
        "    return stats1,votes,pos,ps4_gp,xbox_gp,traits,rat\n",
        " \n",
        "\n",
        "years = [22,21,20,19,18,17,16]\n",
        "ks = [643,598,696,600,654,635,638]\n",
        "for year,pages in zip(years,ks):\n",
        "    get_proxies()\n",
        "    p = 1\n",
        "    final = []\n",
        "    while p != pages:\n",
        "        print(p)\n",
        "        try:\n",
        "            req0 = urlopen(Request(\n",
        "                            url=f\"https://www.futbin.com/{year}/players?page={p}&version=all_nif\",\n",
        "                            headers={'User-Agent': user_agents[randrange(0,len(user_agents))],\n",
        "                                    'referer': 'https://www.google.com'\n",
        "                                    }\n",
        "                        ))\n",
        "            plinks = get_players(req0,year)\n",
        "            for l in plinks:\n",
        "                while True:\n",
        "                    sl = []\n",
        "                    try:\n",
        "                        url = \"https://www.futbin.com/\" + l.get(\"href\")\n",
        "                        req1 = urlopen(Request(\n",
        "                            url,\n",
        "                            headers={'User-Agent': user_agents[randrange(0,len(user_agents))],\n",
        "                                    'referer': 'https://www.google.com'\n",
        "                                    }\n",
        "                        )).read()\n",
        "                        s = pd.read_html(req1,index_col=0)[0]\n",
        "                        stats1,votes,pos,ps4_gp,xbox_gp,traits,rat = get_stats(req1)\n",
        "                        sl.append(rat.contents[0])\n",
        "                        sl.append(pos.contents[0])\n",
        "                        if pos.contents[0] != \"GK\" or year < 19:\n",
        "                            for i in range(0,len(stats1)-1,2):\n",
        "                                sl.append(stats1[i+1].contents[0])\n",
        "                        else:\n",
        "                            for i in range(26,len(stats1)-1,2):\n",
        "                                sl.append(stats1[i+1].contents[0])\n",
        "                        sl+= [traits,ps4_gp,xbox_gp,votes]\n",
        "                        sl = pd.Series(sl, index=columns)\n",
        "                        sl = pd.concat([s[1],sl])\n",
        "                        if type(final) == list:\n",
        "                          if len(final) == 1:\n",
        "                            final.append(sl)\n",
        "                            final = pd.DataFrame(final)\n",
        "                            final.to_csv(f\"/content/drive/MyDrive/FIFA/futbin-{year}-big.csv\", index=False)\n",
        "                          elif len(final) == 0:\n",
        "                            final.append(sl)\n",
        "                          else:\n",
        "                            print(final)\n",
        "                        else:\n",
        "                          sl = sl.to_frame().transpose()\n",
        "                          sl.to_csv(f\"/content/drive/MyDrive/FIFA/futbin-{year}-big.csv\", mode='a', header=False, index=False)\n",
        "                        break\n",
        "                    except Exception as e:\n",
        "                        print(e)\n",
        "                        sleep(5)\n",
        "                        next\n",
        "            p+=1\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            sleep(5)\n",
        "            next"
      ],
      "id": "bb74c6ff"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}